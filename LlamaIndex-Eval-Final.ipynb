{"cells":[{"cell_type":"markdown","id":"cc68eee4-eeb6-4374-bbb3-ee0bf8527f8a","metadata":{"language":"python"},"source":"# Evaluating RAG Pipeline Using LlamaIndex"},{"attachments":{},"cell_type":"markdown","id":"bd1e714d-0bfe-4960-85a7-2aa9137340e7","metadata":{"language":"python"},"source":"## Building a RAG System"},{"cell_type":"code","execution_count":12,"id":"1072201c-bec8-4450-9d60-afb93e5d8e5b","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:52:29.264696Z","iopub.status.busy":"2024-07-21T16:52:29.264454Z","iopub.status.idle":"2024-07-21T16:52:30.855477Z","shell.execute_reply":"2024-07-21T16:52:30.854890Z","shell.execute_reply.started":"2024-07-21T16:52:29.264681Z"},"language":"python","trusted":true},"outputs":[],"source":"!pip install trulens-eval llama-index openai --quiet"},{"cell_type":"code","execution_count":13,"id":"79586bee-8169-4109-83ee-013d0aae3858","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:52:54.010898Z","iopub.status.busy":"2024-07-21T16:52:54.010635Z","iopub.status.idle":"2024-07-21T16:52:54.884056Z","shell.execute_reply":"2024-07-21T16:52:54.883585Z","shell.execute_reply.started":"2024-07-21T16:52:54.010879Z"},"language":"python","trusted":true},"outputs":[],"source":"import nest_asyncio\n\nnest_asyncio.apply()\n\nfrom llama_index.core.evaluation import generate_question_context_pairs\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\nfrom llama_index.core.node_parser import SimpleNodeParser\nfrom llama_index.core.evaluation import generate_question_context_pairs\nfrom llama_index.core.evaluation import RetrieverEvaluator\nfrom llama_index.llms.openai import OpenAI\n\nimport os\nimport pandas as pd"},{"attachments":{},"cell_type":"markdown","id":"d6d654e0-4010-482f-88ae-6df6e4cee193","metadata":{"language":"sql"},"source":"### Mention OpenAI API Key"},{"cell_type":"code","execution_count":14,"id":"94337e5e-109d-4204-8d76-d6f041560a2d","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:53:06.257698Z","iopub.status.busy":"2024-07-21T16:53:06.257411Z","iopub.status.idle":"2024-07-21T16:53:06.260628Z","shell.execute_reply":"2024-07-21T16:53:06.260065Z","shell.execute_reply.started":"2024-07-21T16:53:06.257681Z"},"language":"python","trusted":true},"outputs":[],"source":"import os\n\n# Set your OpenAI API key\nos.environ[\"OPENAI_API_KEY\"] = \"add your OpenAI api key\""},{"attachments":{},"cell_type":"markdown","id":"97e0a3ae-f56e-4cf8-9937-58f59608ad68","metadata":{"language":"python"},"source":"## Download Data"},{"attachments":{},"cell_type":"markdown","id":"21b64267-c8e7-448c-9e12-b3944132e82a","metadata":{"language":"sql"},"source":"Let's use Paul Graham Essay text for building RAG pipeline."},{"cell_type":"code","execution_count":16,"id":"6360a91c-c5e6-49c2-b931-c358b060ff23","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:53:21.669427Z","iopub.status.busy":"2024-07-21T16:53:21.669148Z","iopub.status.idle":"2024-07-21T16:53:22.238944Z","shell.execute_reply":"2024-07-21T16:53:22.238068Z","shell.execute_reply.started":"2024-07-21T16:53:21.669409Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 75042  100 75042    0     0   489k      0 --:--:-- --:--:-- --:--:--  491k\n"}],"source":"!mkdir -p 'data/paul_graham/'\n!curl 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -o 'data/paul_graham/paul_graham_essay.txt'"},{"attachments":{},"cell_type":"markdown","id":"85741a19-e130-4bc2-8454-33b1d41c2f5d","metadata":{"language":"sql"},"source":"## Load Data and Build Index"},{"cell_type":"code","execution_count":18,"id":"daf0f2c5-04b8-4056-be72-4ba850b7d3be","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:54:11.676478Z","iopub.status.busy":"2024-07-21T16:54:11.676226Z","iopub.status.idle":"2024-07-21T16:54:13.189159Z","shell.execute_reply":"2024-07-21T16:54:13.188653Z","shell.execute_reply.started":"2024-07-21T16:54:11.676463Z"},"language":"python","trusted":true},"outputs":[],"source":"documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n\n# Define an LLM\nllm = OpenAI(model=\"gpt-4\")\n\n# Build index with a chunk_size of 512\nnode_parser = SimpleNodeParser.from_defaults(chunk_size=512)\nnodes = node_parser.get_nodes_from_documents(documents)\nvector_index = VectorStoreIndex(nodes)"},{"attachments":{},"cell_type":"markdown","id":"c62229a7-a4de-479a-b6f5-1e64d3744e3c","metadata":{"language":"sql"},"source":"### Build query engine"},{"cell_type":"code","execution_count":19,"id":"3971a4dc-5ab0-4ab3-bb21-61fb967e3c4d","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:55:06.593151Z","iopub.status.busy":"2024-07-21T16:55:06.592890Z","iopub.status.idle":"2024-07-21T16:55:06.596598Z","shell.execute_reply":"2024-07-21T16:55:06.595991Z","shell.execute_reply.started":"2024-07-21T16:55:06.593136Z"},"language":"python","trusted":true},"outputs":[],"source":"query_engine = vector_index.as_query_engine()"},{"cell_type":"code","execution_count":20,"id":"89564eb6-906c-46fb-82ac-c719c2ec6408","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:55:12.742875Z","iopub.status.busy":"2024-07-21T16:55:12.742623Z","iopub.status.idle":"2024-07-21T16:55:13.712039Z","shell.execute_reply":"2024-07-21T16:55:13.711582Z","shell.execute_reply.started":"2024-07-21T16:55:12.742859Z"},"language":"python","trusted":true},"outputs":[],"source":"response_vector = query_engine.query(\"What did the author do growing up?\")"},{"attachments":{},"cell_type":"markdown","id":"0fdbf275-62d4-4b20-806f-9ada715d329f","metadata":{"language":"sql"},"source":"### Check the response"},{"cell_type":"code","execution_count":22,"id":"c6e1ea52-46f9-4801-9620-542908cffa9c","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:55:20.703632Z","iopub.status.busy":"2024-07-21T16:55:20.702951Z","iopub.status.idle":"2024-07-21T16:55:20.711432Z","shell.execute_reply":"2024-07-21T16:55:20.710956Z","shell.execute_reply.started":"2024-07-21T16:55:20.703606Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'The author worked on writing short stories and programming, particularly on an IBM 1401 computer using an early version of Fortran.'"},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":"response_vector.response"},{"attachments":{},"cell_type":"markdown","id":"5935b1cd-0eec-4ad0-94ea-f6bac368a74d","metadata":{"language":"sql"},"source":"## Let's check the text in the retrieved nodes"},{"attachments":{},"cell_type":"markdown","id":"0beed252-9eac-43ed-b182-e4505a147008","metadata":{"language":"sql"},"source":"By default it retrieves two similar nodes/ chunks."},{"cell_type":"code","execution_count":24,"id":"36b8bfff-1cb1-4821-9cf7-db8e7bc15fdc","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:55:35.342736Z","iopub.status.busy":"2024-07-21T16:55:35.342491Z","iopub.status.idle":"2024-07-21T16:55:35.346484Z","shell.execute_reply":"2024-07-21T16:55:35.345949Z","shell.execute_reply.started":"2024-07-21T16:55:35.342721Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed.'"},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"# First retrieved node\nresponse_vector.source_nodes[0].get_text()"},{"cell_type":"code","execution_count":25,"id":"a3f44823-6af2-4134-8a68-20fcbd35a678","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:55:44.157493Z","iopub.status.busy":"2024-07-21T16:55:44.157200Z","iopub.status.idle":"2024-07-21T16:55:44.161395Z","shell.execute_reply":"2024-07-21T16:55:44.160778Z","shell.execute_reply.started":"2024-07-21T16:55:44.157471Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"\"I also worked on spam filters, and did some more painting. I used to have dinners for a group of friends every thursday night, which taught me how to cook for groups. And I bought another building in Cambridge, a former candy factory (and later, twas said, porn studio), to use as an office.\\n\\nOne night in October 2003 there was a big party at my house. It was a clever idea of my friend Maria Daniels, who was one of the thursday diners. Three separate hosts would all invite their friends to one party. So for every guest, two thirds of the other guests would be people they didn't know but would probably like. One of the guests was someone I didn't know but would turn out to like a lot: a woman called Jessica Livingston. A couple days later I asked her out.\\n\\nJessica was in charge of marketing at a Boston investment bank. This bank thought it understood startups, but over the next year, as she met friends of mine from the startup world, she was surprised how different reality was. And how colorful their stories were. So she decided to compile a book of interviews with startup founders.\\n\\nWhen the bank had financial problems and she had to fire half her staff, she started looking for a new job. In early 2005 she interviewed for a marketing job at a Boston VC firm. It took them weeks to make up their minds, and during this time I started telling her about all the things that needed to be fixed about venture capital. They should make a larger number of smaller investments instead of a handful of giant ones, they should be funding younger, more technical founders instead of MBAs, they should let the founders remain as CEO, and so on.\\n\\nOne of my tricks for writing essays had always been to give talks. The prospect of having to stand up in front of a group of people and tell them something that won't waste their time is a great spur to the imagination. When the Harvard Computer Society, the undergrad computer club, asked me to give a talk, I decided I would tell them how to start a startup. Maybe they'd be able to avoid the worst of the mistakes we'd made.\""},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":"# Second retrieved node\nresponse_vector.source_nodes[1].get_text()"},{"cell_type":"markdown","id":"a26c7a06-ec79-4cbf-a4f5-b53cad949a62","metadata":{"language":"python"},"source":"We have built a RAG pipeline and now need to evaluate its performance. Let's make use of LlamaIndex's tools to do that. "},{"attachments":{},"cell_type":"markdown","id":"699b5b83-2cf1-49a6-b42a-020d5f381fb8","metadata":{"language":"sql"},"source":"## Let's generate the question-context pairs for RAG evaluation"},{"cell_type":"code","execution_count":26,"id":"bf04c62c-e767-47c2-ac31-dfa2ab86619d","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:56:11.546628Z","iopub.status.busy":"2024-07-21T16:56:11.546376Z","iopub.status.idle":"2024-07-21T16:59:27.181075Z","shell.execute_reply":"2024-07-21T16:59:27.180497Z","shell.execute_reply.started":"2024-07-21T16:56:11.546610Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 59/59 [03:15<00:00,  3.32s/it]\n"}],"source":"qa_dataset = generate_question_context_pairs(\n    nodes,\n    llm=llm,\n    num_questions_per_chunk=2\n)"},{"attachments":{},"cell_type":"markdown","id":"59857ec7-537e-48b9-9782-588d1e2549a8","metadata":{"language":"sql"},"source":"## Retrieval Evaluation"},{"cell_type":"markdown","id":"81776288-0e83-4f7f-b60a-45eb13498081","metadata":{"language":"python"},"source":"This assesses the accuracy and relevance of the information retrieved by the system."},{"attachments":{},"cell_type":"markdown","id":"14bb7110-11c6-4060-aec5-4509dc17b753","metadata":{"language":"sql"},"source":"Our next step involves initiating retrieval evaluations. We’ll employ the RetrieverEvaluator with the evaluation dataset we’ve prepared."},{"cell_type":"code","execution_count":29,"id":"3a25b458-0bdf-4d22-9189-c9e6bb410c86","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:59:36.047754Z","iopub.status.busy":"2024-07-21T16:59:36.047507Z","iopub.status.idle":"2024-07-21T16:59:36.050604Z","shell.execute_reply":"2024-07-21T16:59:36.050079Z","shell.execute_reply.started":"2024-07-21T16:59:36.047738Z"},"language":"python","trusted":true},"outputs":[],"source":"retriever = vector_index.as_retriever(similarity_top_k=2)"},{"attachments":{},"cell_type":"markdown","id":"1f34317f-3cfa-46af-a69b-4f782cb66152","metadata":{"language":"sql"},"source":"### We use Hit Rate and MRR metrics to evaluate our Retriever.\n\n#### Hit Rate:\nHit rate calculates the fraction of queries where the correct answer is found within the top-k retrieved documents. In simpler terms, it’s about how often our system gets it right within the top few guesses.\n\n#### Mean Reciprocal Rank (MRR):\nMRR serves as a metric for evaluating the accuracy of a system by examining the rank of the highest-placed relevant document for each query. It calculates the average of the reciprocals of these ranks across all queries. For instance, if the first relevant document is ranked highest, the reciprocal rank is 1; if it’s second, the reciprocal rank is 1/2, and so forth."},{"cell_type":"code","execution_count":30,"id":"db01bedc-a7b0-474e-91cf-17c0cd4b6a85","metadata":{"execution":{"iopub.execute_input":"2024-07-21T16:59:45.410057Z","iopub.status.busy":"2024-07-21T16:59:45.409794Z","iopub.status.idle":"2024-07-21T16:59:45.413087Z","shell.execute_reply":"2024-07-21T16:59:45.412495Z","shell.execute_reply.started":"2024-07-21T16:59:45.410043Z"},"language":"python","trusted":true},"outputs":[],"source":"retriever_evaluator = RetrieverEvaluator.from_metric_names(\n    [\"mrr\", \"hit_rate\"], retriever=retriever\n)"},{"cell_type":"code","execution_count":32,"id":"47b01469-e165-44f7-b14b-bbbcff1a3494","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:00:14.955133Z","iopub.status.busy":"2024-07-21T17:00:14.954857Z","iopub.status.idle":"2024-07-21T17:00:23.994855Z","shell.execute_reply":"2024-07-21T17:00:23.994394Z","shell.execute_reply.started":"2024-07-21T17:00:14.955116Z"},"language":"python","trusted":true},"outputs":[],"source":"# Evaluate\neval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"},{"attachments":{},"cell_type":"markdown","id":"607bf6cc-a0bf-4712-99fc-921ba24aa739","metadata":{"language":"sql"},"source":"Let's define a function to display the Retrieval evaluation results in table format"},{"cell_type":"code","execution_count":33,"id":"e2baaad7-bd24-4b1b-b86b-2ddf08e99d8c","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:00:30.593153Z","iopub.status.busy":"2024-07-21T17:00:30.592929Z","iopub.status.idle":"2024-07-21T17:00:30.597205Z","shell.execute_reply":"2024-07-21T17:00:30.596576Z","shell.execute_reply.started":"2024-07-21T17:00:30.593137Z"},"language":"python","trusted":true},"outputs":[],"source":"def display_results(name, eval_results):\n    \"\"\"Display results from evaluate.\"\"\"\n\n    metric_dicts = []\n    for eval_result in eval_results:\n        metric_dict = eval_result.metric_vals_dict\n        metric_dicts.append(metric_dict)\n\n    full_df = pd.DataFrame(metric_dicts)\n\n    hit_rate = full_df[\"hit_rate\"].mean()\n    mrr = full_df[\"mrr\"].mean()\n\n    metric_df = pd.DataFrame(\n        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr]}\n    )\n\n    return metric_df"},{"cell_type":"code","execution_count":34,"id":"c6d3f66f-9d96-40ab-bdd2-856a3605e798","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:00:38.554214Z","iopub.status.busy":"2024-07-21T17:00:38.553964Z","iopub.status.idle":"2024-07-21T17:00:38.564264Z","shell.execute_reply":"2024-07-21T17:00:38.563818Z","shell.execute_reply.started":"2024-07-21T17:00:38.554198Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Retriever Name</th>\n      <th>Hit Rate</th>\n      <th>MRR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OpenAI Embedding Retriever</td>\n      <td>0.813559</td>\n      <td>0.677966</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"               Retriever Name  Hit Rate       MRR\n0  OpenAI Embedding Retriever  0.813559  0.677966"},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":"display_results(\"OpenAI Embedding Retriever\", eval_results)"},{"attachments":{},"cell_type":"markdown","id":"b2fb01f8-e6d8-46ab-ac7e-e4262a659d1e","metadata":{"language":"sql"},"source":"The Retriever with OpenAI Embedding demonstrates a performance with a hit rate of 0.813559, while the MRR, at 0.677966, suggests there's room for improvement in ensuring the most relevant results appear at the top. "},{"cell_type":"markdown","id":"b5210335-333c-47b8-ab7b-bec5113ad8fe","metadata":{"language":"python"},"source":"## Response Evaluation"},{"cell_type":"markdown","id":"bff4d8c6-315b-405d-bc0b-b472eb9e6996","metadata":{"language":"python"},"source":"This measures the quality and appropriateness of the responses generated by the system based on the retrieved information."},{"cell_type":"code","execution_count":35,"id":"c1cfbf87-6a5f-49b8-9825-5a3b5b2380a8","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:00:57.785279Z","iopub.status.busy":"2024-07-21T17:00:57.784999Z","iopub.status.idle":"2024-07-21T17:00:57.788070Z","shell.execute_reply":"2024-07-21T17:00:57.787491Z","shell.execute_reply.started":"2024-07-21T17:00:57.785264Z"},"language":"python","trusted":true},"outputs":[],"source":"# Get the list of queries from the above created dataset\n\nqueries = list(qa_dataset.queries.values())"},{"attachments":{},"cell_type":"markdown","id":"f05b7c04-2698-44e4-82e8-3c2b4427db22","metadata":{"language":"sql"},"source":"### Faithfulness Evaluator"},{"attachments":{},"cell_type":"markdown","id":"e091fb47-bc11-440b-94eb-21587f426889","metadata":{"language":"sql"},"source":"We will use gpt-3.5-turbo it for generating responses for a given query gpt-3.5-turbo-16k-0613 and gpt-4 for evaluation."},{"cell_type":"code","execution_count":41,"id":"4855237d-b5c6-4ed5-afe6-4997d38a3a7a","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:02:35.335477Z","iopub.status.busy":"2024-07-21T17:02:35.335054Z","iopub.status.idle":"2024-07-21T17:02:35.340997Z","shell.execute_reply":"2024-07-21T17:02:35.340390Z","shell.execute_reply.started":"2024-07-21T17:02:35.335458Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":"/tmp/ipykernel_158/1567755451.py:2: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n  service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n/tmp/ipykernel_158/1567755451.py:5: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n  service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n/tmp/ipykernel_158/1567755451.py:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n  service_context_gpt4 = ServiceContext.from_defaults(llm=gpt35T)\n"}],"source":"gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\nservice_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n\ngpt4 = OpenAI(temperature=0, model=\"gpt-3.5-turbo-16k-0613\")\nservice_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n\ngpt35T = OpenAI(temperature=0, model=\"gpt-4\")\nservice_context_gpt4 = ServiceContext.from_defaults(llm=gpt35T)"},{"attachments":{},"cell_type":"markdown","id":"84290555-acde-431d-b1a3-b392454efbfb","metadata":{"language":"sql"},"source":"Create a QueryEngine with gpt-3.5-turbo service_context to generate response for the query."},{"cell_type":"code","execution_count":42,"id":"75f9954e-67b5-4150-a22d-cff3fdcebef4","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:03:02.492746Z","iopub.status.busy":"2024-07-21T17:03:02.492497Z","iopub.status.idle":"2024-07-21T17:03:03.025013Z","shell.execute_reply":"2024-07-21T17:03:03.024499Z","shell.execute_reply.started":"2024-07-21T17:03:02.492730Z"},"language":"python","trusted":true},"outputs":[],"source":"vector_index = VectorStoreIndex(nodes, service_context = service_context_gpt35)\nquery_engine = vector_index.as_query_engine()"},{"attachments":{},"cell_type":"markdown","id":"a9d6da2c-4bc5-44ef-8386-a014773a4858","metadata":{"language":"sql"},"source":"#### Let's create a FaithfulnessEvaluator and evaluate on one question"},{"cell_type":"code","execution_count":43,"id":"fd704c07-9de0-4c27-82aa-a3eaaaba693a","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:03:13.864570Z","iopub.status.busy":"2024-07-21T17:03:13.864283Z","iopub.status.idle":"2024-07-21T17:03:13.868233Z","shell.execute_reply":"2024-07-21T17:03:13.867576Z","shell.execute_reply.started":"2024-07-21T17:03:13.864553Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Based on the author's experience and observations, why did he conclude that the approach to Artificial Intelligence during his time in grad school was a hoax? Provide specific examples from the text to support your answer.\n"}],"source":"from llama_index.core.evaluation import FaithfulnessEvaluator\nfaithfulness_gpt4 = FaithfulnessEvaluator(service_context=service_context_gpt4)\n\neval_query = queries[10]\n\nprint(eval_query)"},{"attachments":{},"cell_type":"markdown","id":"421cb5e3-cad3-428b-a6ef-4aa789fb778c","metadata":{"language":"sql"},"source":"#### Generate response first and use faithfull evaluator"},{"cell_type":"code","execution_count":44,"id":"e145fc19-4cf0-4048-a41a-5565a823d3c6","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:03:51.907170Z","iopub.status.busy":"2024-07-21T17:03:51.906921Z","iopub.status.idle":"2024-07-21T17:03:54.294189Z","shell.execute_reply":"2024-07-21T17:03:54.293650Z","shell.execute_reply.started":"2024-07-21T17:03:51.907155Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"True"},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":"response_vector = query_engine.query(eval_query)\n\neval_result = faithfulness_gpt4.evaluate_response(response=response_vector)\n\neval_result.passing"},{"attachments":{},"cell_type":"markdown","id":"ba448bad-2ad8-42eb-8385-49bbc2bcc3eb","metadata":{"language":"sql"},"source":"### Relevancy Evaluator"},{"attachments":{},"cell_type":"markdown","id":"4a4dc01b-b8b3-49f5-913b-1458ccde238b","metadata":{"language":"sql"},"source":"RelevancyEvaluator is useful to measure if the response and source nodes (retrieved context) match the query. Useful to see if response actually answers the query.\n\nInstantiate RelevancyEvaluator for relevancy evaluation with gpt-4"},{"cell_type":"code","execution_count":45,"id":"49b4dbf3-92b3-462e-b68f-9a4e7862eb2f","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:04:06.966418Z","iopub.status.busy":"2024-07-21T17:04:06.966168Z","iopub.status.idle":"2024-07-21T17:04:06.969205Z","shell.execute_reply":"2024-07-21T17:04:06.968569Z","shell.execute_reply.started":"2024-07-21T17:04:06.966402Z"},"language":"python","trusted":true},"outputs":[],"source":"from llama_index.core.evaluation import RelevancyEvaluator\nrelevancy_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)"},{"attachments":{},"cell_type":"markdown","id":"1b4ad982-c56a-4f19-882e-94ba84576c8c","metadata":{"language":"sql"},"source":"Let's do relevancy evaluation for one of the query"},{"cell_type":"code","execution_count":49,"id":"2885bfa0-7d8b-445f-98e9-3c6ef21707d0","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:05:19.613000Z","iopub.status.busy":"2024-07-21T17:05:19.611287Z","iopub.status.idle":"2024-07-21T17:05:21.735327Z","shell.execute_reply":"2024-07-21T17:05:21.734863Z","shell.execute_reply.started":"2024-07-21T17:05:19.612976Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Based on the author's experience and observations, why did he conclude that the approach to Artificial Intelligence during his time in grad school was a hoax? Provide specific examples from the text to support your answer.\n"}],"source":"query = queries[10]\n\nprint(query)\n\nresponse_vector = query_engine.query(query)\n\neval_result = relevancy_gpt4.evaluate_response(\n    query=query, response=response_vector\n)"},{"cell_type":"code","execution_count":72,"id":"62cc24d6-5577-4c2b-bf4c-509069a5395d","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:31:21.509745Z","iopub.status.busy":"2024-07-21T17:31:21.509320Z","iopub.status.idle":"2024-07-21T17:31:21.512489Z","shell.execute_reply":"2024-07-21T17:31:21.511936Z","shell.execute_reply.started":"2024-07-21T17:31:21.509728Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"True\n"}],"source":"# You can check passing parameter in eval_result if it passed the evaluation.\nresult = eval_result.passing\nprint(result)"},{"cell_type":"code","execution_count":73,"id":"6df3dcb1-e3d5-40d7-a71f-5f0b8b358187","metadata":{"execution":{"iopub.execute_input":"2024-07-21T17:31:24.305133Z","iopub.status.busy":"2024-07-21T17:31:24.304884Z","iopub.status.idle":"2024-07-21T17:31:24.308017Z","shell.execute_reply":"2024-07-21T17:31:24.307472Z","shell.execute_reply.started":"2024-07-21T17:31:24.305116Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"YES\n"}],"source":"# You can get the feedback for the evaluation.\nfeedback = eval_result.feedback\nprint(feedback)"},{"attachments":{},"cell_type":"markdown","id":"69e0e5c7-6ea7-469b-aa8c-341cc0cf546d","metadata":{"language":"sql"},"source":"In this notebook, we have explored how to build and evaluate a RAG pipeline using LlamaIndex, with a specific focus on evaluating the retrieval system and generated responses within the pipeline."}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"77746612-3eb9-447b-b400-efdec97e2064","defaultDatabase":"ragdb"},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}